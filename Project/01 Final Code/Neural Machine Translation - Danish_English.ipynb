{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#imports\nimport re\nimport tensorflow as tf\nimport numpy as np\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, GRU, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mark_start = \"SSSS \"\nmark_end = \" EEEE\"\ndef readDanishfile(filename):\n        data = []\n        with open(filename) as file:\n            for line in file:\n                line = line.rstrip('\\n')\n                data.append(line)\n        return data\n\ndef readEnglishfile(filename):\n        data = []\n        with open(filename) as file:\n            for line in file:\n                line = line.rstrip('\\n')\n                line = mark_start+line+mark_end\n                data.append(line)\n        return data\n\neng_data = readEnglishfile(\"../input/enlish_data.txt\")\nda_data = readDanishfile(\"../input/danish-data.txt\")\nnum_words = 10000","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eng_data[:5])","execution_count":25,"outputs":[{"output_type":"stream","text":"['SSSS Resumption of the session EEEE', 'SSSS I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period. EEEE', \"SSSS Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful. EEEE\", 'SSSS You have requested a debate on this subject in the course of the next few days, during this part-session. EEEE', \"SSSS In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union. EEEE\"]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inspired by open source code from keras models\n# https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/text.py\nclass Wrapper(Tokenizer):\n    \n    def __init__(self,texts,padding,reverse=False,num_words=None):\n        \n        Tokenizer.__init__(self,num_words=num_words)\n        \n        self.fit_on_texts(texts)\n        \n        self.tokens = self.texts_to_sequences(texts)\n          \n        self.index_to_word = dict(zip(self.word_index.values(), self.word_index.keys()))\n        \n        self.num_tokens = [len(x) for x in self.tokens]\n        \n        self.max_tokens = np.mean(self.num_tokens) + 2*np.std(self.num_tokens)\n        \n        self.max_tokens  = int(self.max_tokens)\n        \n        if reverse:\n            self.tokens = [list(reversed(x)) for x in self.tokens]\n            truncating = 'pre'\n        else:\n            truncating = 'post'\n        \n        self.tokens_padded = pad_sequences(self.tokens, maxlen= self.max_tokens, padding=padding,truncating=truncating)\n    \n    def tokens_to_string(self,tokens):\n        words = [self.index_to_word[token] for token in tokens if token !=0]\n        sentence = \"\".join(words)\n        return sentence\n    \n    def token_to_word(self,token):\n        word = \" \" if token == 0 else self.index_to_word[token]\n        return word\n    \n    def text_to_tokens(self,text,reverse=False,padding=False):\n        tokens = self.texts_to_sequences([text])\n        tokens = np.array(tokens)\n        if reverse:\n            tokens =np.flip(tokens,axis=1)\n            truncating =\"pre\"\n        else:\n            truncating = \"post\"\n        \n        if padding:\n            tokens = pad_sequences(tokens,\n                                  maxlen=self.max_tokens,\n                                  padding=\"pre\",\n                                  truncating = truncating)\n            return tokens","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/text.py\n# Properties of machine translation https://arxiv.org/pdf/1409.1259.pdf\nda_tokenizer = Wrapper(texts=da_data[:100000],padding=\"pre\",reverse=True, num_words=num_words)\neng_tokenizer = Wrapper(texts=eng_data[:100000],padding=\"post\",reverse=False, num_words=num_words)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_tokens = eng_tokenizer.tokens_padded\nprint(eng_tokens[:1])","execution_count":49,"outputs":[{"output_type":"stream","text":"[[   2 4535    4    1  928    3    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_start = 2\ntoken_end = 3","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"da_tokens = da_tokenizer.tokens_padded\neng_tokens = eng_tokenizer.tokens_padded\nprint(eng_tokens.shape)\nprint(da_tokens.shape)","execution_count":51,"outputs":[{"output_type":"stream","text":"(50000, 57)\n(50000, 50)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eng_tokenizer.token_to_word(1))","execution_count":52,"outputs":[{"output_type":"stream","text":"the\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift technique for providing decoder data\n# https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\nencoder_input_data = da_tokens\ndecoder_input_data = eng_tokens[:, :-1]\ndecoder_output_data = eng_tokens[:, 1:]","execution_count":53,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building encoder neural architecture  \n1. Reference:  \nKeras documentation: https://keras.io/layers/about-keras-layers/  \nKeras open source code: https://github.com/keras-team/keras/blob/master/keras/layers/core.py#L796  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# building the basic blocks\nencoder_input = Input(shape=(None,), name=\"encoder_input\")\nembedding_size = 128\nencoder_embedding = Embedding(input_dim=num_words,output_dim=embedding_size, name=\"encoder_embedding\")\nstate_size = 512\n\n# we need single thoughtVector for gru processing\nE_GRU1 = GRU(state_size, name='E_GRU1',return_sequences=True)\nE_GRU2 = GRU(state_size, name='E_GRU2',return_sequences=True)\nE_GRU3 = GRU(state_size, name='E_GRU3', return_sequences=False)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assembling the encoder\ndef assemble_encoder():\n    # encoder input layer\n    nn = encoder_input\n    \n    # embedding layer\n    nn = encoder_embedding(nn)\n\n    # GRU connections.\n    nn = E_GRU1(nn)\n    nn = E_GRU2(nn)\n    nn = E_GRU3(nn)\n    \n    encoder_output = nn\n    \n    return encoder_output\n\n# return encoder assembled model\nencoder_output = assemble_encoder()","execution_count":55,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building decoder neural architecture  \n1. Reference:  \nKeras documentation: https://keras.io/layers/about-keras-layers/    \nKeras open source code: https://github.com/keras-team/keras/blob/master/keras/layers/core.py#L796   "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic building blocks inspired by keras open source layers documentation\ndecoder_initial_state = Input(shape=(state_size,), name='decoder_initial_state')\ndecoder_input = Input(shape=(None, ), name='decoder_input')\ndecoder_embedding = Embedding(input_dim=num_words,output_dim=embedding_size, name='decoder_embedding')\n\n# decoder GRUs to give multivector output\n# inspired by https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\nD_GRU1 = GRU(state_size, name='D_GRU1', return_sequences=True)\nD_GRU2 = GRU(state_size, name='D_GRU2', return_sequences=True)\nD_GRU3 = GRU(state_size, name='D_GRU3', return_sequences=True)\n\ndecoder_dense = Dense(num_words, activation='linear', name='decoder_output')","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assembling decoder with initial state\ndef assemble_decoder(initial_state):\n    \n    #decoder input stage with english tokens shifted by 1\n    nn = decoder_input\n\n    # Embedding layer\n    nn = decoder_embedding(nn)\n    \n    # Connect all the GRU-layers.\n    nn = D_GRU1(nn, initial_state=initial_state)\n    nn = D_GRU2(nn, initial_state=initial_state)\n    nn = D_GRU3(nn, initial_state=initial_state)\n    \n    # dense layer\n    decoder_output = decoder_dense(nn)\n    \n    return decoder_output\n\n# assembled decoder model\ndecoder_output = assemble_decoder(initial_state=encoder_output)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reference: Keras Model API\n\n# Complete architecture\nDA_ENG_MODEL = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n\n#Encoder Model\nmodel_encoder = Model(inputs=[encoder_input],outputs=[encoder_output])\n\n# Decoder output\ndecoder_output = assemble_decoder(initial_state=decoder_initial_state)\n\n# Decoder Model\nmodel_decoder = Model(inputs=[decoder_input, decoder_initial_state],outputs=[decoder_output])\n","execution_count":58,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loss function: sparse cross entroy loss  \nReference:  \nhttps://keras.io/losses/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining sparse cross entropy loss\n# reference: https://github.com/keras-team/keras/tree/master/docs\ndef sparse_cross_entropy(y_true, y_pred):\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n    loss_mean = tf.reduce_mean(loss)\n    return loss_mean","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RMSprop optimizer\noptimizer = RMSprop(lr=1e-3)\ndecoder_target = tf.placeholder(dtype='int32', shape=(None, None))\n\n#compiling model\nDA_ENG_MODEL.compile(optimizer=optimizer,loss=sparse_cross_entropy, target_tensors=[decoder_target])","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data = \\\n{\n    'encoder_input': encoder_input_data,\n    'decoder_input': decoder_input_data\n}\n\ny_data = \\\n{\n    'decoder_output': decoder_output_data\n}\n\nvalidation_split = 10000 / len(encoder_input_data)\nprint(validation_split)","execution_count":61,"outputs":[{"output_type":"stream","text":"0.2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"DA_ENG_MODEL.fit(x=x_data, y=y_data, batch_size=512, epochs=1, validation_split=validation_split)","execution_count":62,"outputs":[{"output_type":"stream","text":"Train on 40000 samples, validate on 10000 samples\nEpoch 1/1\n40000/40000 [==============================] - 50s 1ms/step - loss: 3.7148 - val_loss: 3.0183\n","name":"stdout"},{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"<keras.callbacks.History at 0x7f2e7888c5f8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Translate text by index in danish source language\n# inspired by https://stackoverflow.com/questions/41971587/how-to-convert-predicted-sequence-back-to-text-in-keras\ndef translate(input_text, true_output_text=None):\n    #input tokens\n    input_tokens = da_tokenizer.text_to_tokens(text=input_text,reverse=True,padding=True)\n    \n    #predict the result throught encoder\n    initial_state = model_encoder.predict(input_tokens)\n\n    #max_tokens for english\n    max_tokens = eng_tokenizer.max_tokens\n\n    shape = (1, max_tokens)\n    decoder_input_data = np.zeros(shape=shape, dtype=np.int)\n\n    token_int = token_start\n\n    output_text = ''\n\n    count_tokens = 0\n\n    while token_int != token_end and count_tokens < max_tokens:\n        decoder_input_data[0, count_tokens] = token_int\n\n        x_data = \\\n        {\n            'decoder_initial_state': initial_state,\n            'decoder_input': decoder_input_data\n        }\n\n        decoder_output = model_decoder.predict(x_data)\n        token_onehot = decoder_output[0, count_tokens, :]\n        \n        token_int = np.argmax(token_onehot)\n        sampled_word = eng_tokenizer.token_to_word(token_int)\n\n        try:\n            output_text += \" \" + sampled_word\n        except:\n            output_text += \"\"\n        count_tokens += 1\n        \n    output_tokens = decoder_input_data[0]\n    \n    print(\"Input text:\")\n    print(input_text)\n    print()\n\n    print(\"Translated text:\")\n    print(output_text)\n    print()\n\n    if true_output_text is not None:\n        print(\"True output text:\")\n        print(true_output_text)\n        print()","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 2\ntranslate(input_text=da_data[x],true_output_text=eng_data[x])","execution_count":66,"outputs":[{"output_type":"stream","text":"Input text:\nSom De kan se, indfandt det store \"år 2000-problem\" sig ikke. Til gengæld har borgerne i en del af medlemslandene været ramt af meget forfærdelige naturkatastrofer.\n\nTranslated text:\n i the the the the the the                                                                                                    \n\nTrue output text:\nSSSS Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful. EEEE\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}